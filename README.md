# HACKATHON-AMERICA — Player Scouting & Lineup Toolkit

Interactive lineup/scouting app + notebooks to build role-weighted profiles, clusters, and network-effect “what-ifs.”
All derived files are created by `hackathon_clean_export.ipynb` into `artifacts/`, which is git-ignored.

## Contents

* [Repo structure](#repo-structure)
* [Quick start](#quick-start)
* [Secrets & configuration](#secrets--configuration)
* [Data flow & artifacts](#data-flow--artifacts)
* [Models](#models)
* [Methodologies](#methodologies)
* [App tabs](#app-tabs)
* [Reproducibility](#reproducibility)
* [Troubleshooting](#troubleshooting)
* [License](#license)

---

## Repo structure

```
HACKATHON-AMERICA/
├─ .venv/                      # local virtualenv (optional, untracked)
├─ artifacts/                  # GENERATED by hackathon_clean_export.ipynb (untracked)
├─ data/                       # raw or interim inputs you own locally
├─ modules/                    # reusable Python modules for the app/notebooks
├─ old/                        # scratch/legacy
├─ .env                        # local secrets (untracked)
├─ .gitignore
├─ app.py                      # Streamlit app
├─ eda_hackathon.ipynb         # exploratory analysis
├─ hackathon_clean_export.ipynb# builds/exports artifacts/*
├─ README.md
└─ requirements.txt
```

**Important:** `artifacts/` and `.env` are not committed. The app reads prepared data from `artifacts/`.

---

## Quick start

### 1) Environment

```bash
python -m venv .venv
source .venv/bin/activate           # Windows: .venv\Scripts\activate
pip install -U pip
pip install -r requirements.txt
```

### 2) Secrets

Create a local `.env` at the repo root (see [Secrets & configuration](#secrets--configuration)).
Nothing sensitive is committed.

### 3) Build artifacts

Run the notebook that creates everything the app needs:

* Open **`hackathon_clean_export.ipynb`** and run all cells; or
* Convert to a script and run headless (optional):

  ```bash
  jupyter nbconvert --to notebook --execute hackathon_clean_export.ipynb \
                    --output hackathon_clean_export_out.ipynb
  ```

You should now have fresh files inside `artifacts/`.

### 4) Launch the app

```bash
streamlit run app.py
```

---

## Secrets & configuration

Use a **.env** file at the repo root. Typical keys:

```env
# App/runtime
APP_ENV=dev
LOG_LEVEL=INFO

# Artifacts path override (optional; default is ./artifacts)
ARTIFACTS_DIR=./artifacts

# Provider/API credentials (if used in notebooks or app)
SB_USERNAME=you@example.com
SB_PASSWORD=supersecret
```

**How the app pulls secrets:**
The codebase uses a lightweight pattern (`python-dotenv` + `os.getenv`) or a small settings wrapper. Minimal usage inside `app.py` / `modules/*`:

```python
from pathlib import Path
import os
from dotenv import load_dotenv

load_dotenv()  # loads .env from repo root

ARTIFACTS_DIR = Path(os.getenv("ARTIFACTS_DIR", "./artifacts"))
SB_USER = os.getenv("SB_USERNAME", "")
SB_PASS = os.getenv("SB_PASSWORD", "")
```

> If you later switch to a Pydantic settings loader, it will still read the same `.env`.

---

## Data flow & artifacts

**Source inputs**

* `data/` contains raw or intermediate inputs (local only).
* Optional API calls (e.g., StatsBomb lineups) use `SB_USERNAME`/`SB_PASSWORD` when needed.

**Notebook pipeline**

* `hackathon_clean_export.ipynb` is the **single source of truth** that:

  1. Loads and cleans raw inputs.
  2. Computes per-90 features and role-weighted (RW) profiles.
  3. Trains/assigns clusters and saves labels.
  4. Exports app-ready tables into `artifacts/`.

**Outputs (examples)**

* `artifacts/players_meta.parquet` — player_id, names, age, positions, mins, etc.
* `artifacts/per90.parquet` — canonical per-90 feature matrix.
* `artifacts/rw_profiles.parquet` — per-90 × role weights.
* `artifacts/player_clusters.parquet` — cluster_id per player + label.
* `artifacts/cluster_info.parquet` — centroids, top features, representative players.
* `artifacts/lookups.parquet` — position maps, team maps, etc.
* `artifacts/app_cache.pkl` — optional precomputed similarity indices / scalers.
* Any other tables the app expects (documented inline in the notebook).

> The app **does not** compute heavy features at runtime; it reads the exports above.

---

## Models

1. **Per-90 Normalization**

   * Minutes floor (e.g., 450) to limit small-sample noise.
   * Auto-detected columns with suffix `_per90`.

2. **Role-Weighted (RW) Profiles**

   * Weights per-90 stats by positional importance inside a role family.
   * Produces `_per90_rw` vectors for similarity search and clustering.

3. **Clustering**

   * Interpretable player-type clusters (e.g., *Libero*, *False 9*, *Ball-playing CB*, *Creator 10*).
   * Configurable `n_clusters`; centroids saved for inspection.

4. **Network Effects (Counterfactual Swaps)**

   * Simulates teammate deltas when swapping players (usage/fit propagation).
   * Exposes an **Impact Gain** knob to scale spillovers.

---

## Methodologies

* **Standardization**: z-scaling before clustering/RW if needed.
* **RW construction**: domain-informed weights per position/role group.
* **Cluster naming**: classical football vocabulary (not “low-output/runner”).
* **Counterfactuals**:

  * Baseline lineup vectors → swap → propagate deltas through role adjacency and on-ball usage.
  * Report **Team Δ** plus aggregate **Helped** vs **Hurt** teammate effects.

---

## App tabs

* **Lineup Builder**
  Pick XI, see per-player bars and a team total banner.

* **Swaps & Network Effects**
  Drop-in replacements; BIG current-vs-baseline delta.
  One compact table showing **Teammates Helped** (green) and **Teammates Hurt** (red) as aggregated rows.

* **Player Search**
  Filter by position, **main position**, cluster, team.
  RW similarity search to find analogs.

* **Similar Player Search**
  Find most similar players to other player.

* **Clusters**
  Explore clusters: centroid traits, exemplars, label descriptions.

* **Comparisons**
  H2H charts (per-90 vs RW toggles).

---

## Reproducibility

1. Pin dependencies:

   ```bash
   pip freeze > requirements.txt
   ```
2. Re-run `hackathon_clean_export.ipynb` after any data/model change.
3. Commit only code + templates:

   * `artifacts/` stays local (generated).
   * `.env` stays local (secrets).

**.gitignore (key lines)**

```
.env
artifacts/
__pycache__/
*.pyc
.ipynb_checkpoints/
```

---

## Troubleshooting

* **App can’t find artifacts**
  Ensure you ran `hackathon_clean_export.ipynb` and that `ARTIFACTS_DIR` points to the folder.

* **Filters for Position/Main Position/Cluster look empty**
  Check that `players_meta.parquet`, `player_clusters.parquet`, and the RW tables include those columns and non-null values.

* **Credentials errors on API calls**
  Confirm `.env` exists at the repo root and keys are set. Restart the app after edits.

* **Memory issues when exporting**
  Run the notebook kernel once, process in batches, or persist intermediate parquet files under `artifacts/`.

---

## License

MIT (or your preferred license).
© You — for research/educational use; verify redistribution rights for any 3rd-party data.